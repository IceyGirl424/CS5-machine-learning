{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "9469411d",
      "cell_type": "markdown",
      "source": "# CS 5 - Spring 2025 - Machine Learning Final Project Proposal\n\n**Project Title**: <span style=\"color: blue\">Predicting Mental Health Treatment-Seeking Behavior Using Workplace and Lifestyle Factors</span>\n\n**Project Member(s)**: <span style=\"color: blue\">Lena Munad (individual)</span>",
      "metadata": {}
    },
    {
      "id": "d3764b3b",
      "cell_type": "markdown",
      "source": "## Introduction\nThis project explores how workplace environment, personal history, and lifestyle habits influence mental health support-seeking behavior among tech employees. Using data from a mental health survey, we aim to build machine learning models to predict whether someone has sought mental health treatment.\n\nThis binary classification problem will be tackled using three supervised learning algorithms from this course: k-Nearest Neighbors (k-NN), Naïve Bayes (GaussianNB), and Support Vector Machines (SVM). The results will help us compare performance and interpret which factors are most predictive.\n",
      "metadata": {}
    },
    {
      "id": "e771d5b6",
      "cell_type": "markdown",
      "source": "## Imports",
      "metadata": {}
    },
    {
      "id": "f947f892",
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c0c563db",
      "cell_type": "markdown",
      "source": "## Domain\nThe dataset used in this project is from Kaggle: [Mental Health in Tech Survey](https://www.kaggle.com/datasets/osmi/mental-health-in-tech-survey). It contains self-reported responses from tech workers on:\n\n- Mental health history and treatment\n- Employer support and workplace culture\n- Comfort discussing mental health\n- Demographics like age, gender, and work setup\n\nThe target variable is: **“Have you sought treatment for a mental health condition?”** (Yes/No). We'll clean, encode, and preprocess the data to prepare it for modeling.\n",
      "metadata": {}
    },
    {
      "id": "3091d625",
      "cell_type": "markdown",
      "source": "## ML Algorithm #1\n### Algorithm 1: k-Nearest Neighbors (k-NN)\n\nk-NN will be used as a baseline model. It classifies a data point based on the majority class of its `k` closest neighbors. Since k-NN is sensitive to feature scaling, normalization will be applied. We'll explore different `k` values to optimize performance.\n",
      "metadata": {}
    },
    {
      "id": "198b24db",
      "cell_type": "markdown",
      "source": "## ML Algorithm #2\n### Algorithm 2: Naïve Bayes (GaussianNB)\n\nNaïve Bayes applies Bayes' Theorem under the assumption that features are conditionally independent. We'll use the GaussianNB classifier for this dataset after encoding categorical variables. It is computationally efficient and effective for high-bias scenarios.\n",
      "metadata": {}
    },
    {
      "id": "9e0fd416",
      "cell_type": "markdown",
      "source": "## ML Algorithm #3\n### Algorithm 3: Support Vector Machine (SVM)\n\nSVM will be used to build a model that can separate data points with a maximum margin hyperplane. After scaling the features, we’ll train an SVM and experiment with kernel options and parameters to improve prediction accuracy.\n",
      "metadata": {}
    },
    {
      "id": "3852c0da",
      "cell_type": "markdown",
      "source": "## Results and Analysis\nWe will evaluate the performance of each model using:\n\n- Accuracy\n- Precision, Recall, and F1 Score\n- Confusion Matrix\n\nVisualizations will be provided where useful, and models will be compared based on performance and interpretability. We'll also note which features contributed most to predictions.\n",
      "metadata": {}
    },
    {
      "id": "9b6c24b3",
      "cell_type": "markdown",
      "source": "## Conclusion\nThe conclusion will summarize our findings from model evaluations. We'll discuss:\n\n- Which model performed best\n- The most important features influencing mental health treatment-seeking\n- Ethical considerations and real-world implications for using ML in mental health contexts\n",
      "metadata": {}
    }
  ]
}