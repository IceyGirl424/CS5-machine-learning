{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a51a0ccd-4507-47cd-b37b-51f4fffd83f6",
   "metadata": {},
   "source": [
    "# Lab 5\n",
    "\n",
    "**Due Date**: 2/26/25 by 8pm on Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39f0a48-d76a-4abf-a93b-44e6e5b923e4",
   "metadata": {},
   "source": [
    "## Installing Libraries\n",
    "\n",
    "Machine learning in Python has a plethora of popularly used libraries. We can install these library packages within the Jupyter Notebooks itself. Just run the cell below and it should download and install them to your computer. You only need to run this cell one time. After the package has been installed, feel free to change the cell type below from \"Code\" to \"Raw\" so it doesn't run this again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5632a0a0-4b14-4ed1-8265-707da4eeef64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in /opt/anaconda3/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/anaconda3/lib/python3.11/site-packages (from gymnasium) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from gymnasium) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from gymnasium) (4.9.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from gymnasium) (0.0.4)\n",
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /opt/anaconda3/lib/python3.11/site-packages (from stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in /opt/anaconda3/lib/python3.11/site-packages (from stable-baselines3[extra]) (1.26.4)\n",
      "INFO: pip is looking at multiple versions of stable-baselines3[extra] to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading stable_baselines3-2.4.1-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: torch>=1.13 in /opt/anaconda3/lib/python3.11/site-packages (from stable-baselines3[extra]) (2.2.2)\n",
      "Requirement already satisfied: cloudpickle in /opt/anaconda3/lib/python3.11/site-packages (from stable-baselines3[extra]) (2.2.1)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (from stable-baselines3[extra]) (2.1.4)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.11/site-packages (from stable-baselines3[extra]) (3.8.0)\n",
      "Collecting opencv-python (from stable-baselines3[extra])\n",
      "  Downloading opencv-python-4.11.0.86.tar.gz (95.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pygame (from stable-baselines3[extra])\n",
      "  Downloading pygame-2.6.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
      "Collecting tensorboard>=2.9.1 (from stable-baselines3[extra])\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.11/site-packages (from stable-baselines3[extra]) (5.9.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from stable-baselines3[extra]) (4.65.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.11/site-packages (from stable-baselines3[extra]) (13.3.5)\n",
      "Collecting ale-py>=0.9.0 (from stable-baselines3[extra])\n",
      "  Downloading ale_py-0.10.2-cp311-cp311-macosx_10_15_x86_64.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.11/site-packages (from stable-baselines3[extra]) (10.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra]) (4.9.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
      "Collecting absl-py>=0.4 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Downloading grpcio-1.70.0-cp311-cp311-macosx_10_14_universal2.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.4.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.2.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3[extra]) (3.13.1)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3[extra]) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3[extra]) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.13->stable-baselines3[extra]) (2023.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->stable-baselines3[extra]) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->stable-baselines3[extra]) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->stable-baselines3[extra]) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->stable-baselines3[extra]) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->stable-baselines3[extra]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->stable-baselines3[extra]) (2023.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->stable-baselines3[extra]) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->stable-baselines3[extra]) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->stable-baselines3[extra]) (0.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
      "Downloading ale_py-0.10.2-cp311-cp311-macosx_10_15_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pygame-2.6.1-cp311-cp311-macosx_10_9_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading stable_baselines3-2.4.1-py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.70.0-cp311-cp311-macosx_10_14_universal2.whl (11.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: opencv-python\n",
      "  Building wheel for opencv-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for opencv-python: filename=opencv_python-4.11.0.86-cp311-cp311-macosx_10_16_x86_64.whl size=27451529 sha256=bd65602ea881fe78c74c3cfd2f326b44c80debb4bcd8cceb1e711cb3412ac7ae\n",
      "  Stored in directory: /Users/alinapanther/Library/Caches/pip/wheels/28/fc/1b/8a5c9932451af486aed6ccb7c346243edda1010175f281d6b8\n",
      "Successfully built opencv-python\n",
      "Installing collected packages: tensorboard-data-server, pygame, opencv-python, grpcio, ale-py, absl-py, tensorboard, stable-baselines3\n",
      "Successfully installed absl-py-2.1.0 ale-py-0.10.2 grpcio-1.70.0 opencv-python-4.11.0.86 pygame-2.6.1 stable-baselines3-2.4.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{'\"' + sys.executable + '\"'} -m pip install gymnasium\n",
    "!{'\"' + sys.executable + '\"'} -m pip install \"stable-baselines3[extra]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a0050f-6bd9-4939-b9fe-dbe0957ab99c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad927042-9550-423d-9409-eb01aa658c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8146855-3691-47c8-a867-a73a9e01e416",
   "metadata": {},
   "source": [
    "## The Environment\n",
    "\n",
    "In reinforcement learning, our AI agent is going to be interacting with an environment. We will be using the Gymansium library to handle creating a virtual environment for us. Specifically, we are going to use the classic Cart Pole problem. You can choose whether or not to render the environment by changing the flag value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c0a0d9d-21c2-4d5d-a3ec-de696b776a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_flag = True\n",
    "\n",
    "if render_flag:\n",
    "    env = gym.make('CartPole-v1', render_mode='human')\n",
    "else:\n",
    "    env = gym.make('CartPole-v1')\n",
    "    env.reset()\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5350874b-8770-482e-985d-1de3a0794172",
   "metadata": {},
   "source": [
    "## RL Agent\n",
    "\n",
    "With the environment generated for us, let's focus on the RL. We will be using the Stable Baselines3 (SB3) library for this purpose. This is a set of reliable implementations of reinforcement learning algorithms in PyTorch.\n",
    "\n",
    "Research on how to create a RL agent that uses the [PPO (Proximal Policy Optimization) algorithm in SB3](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html). FYI, this algorithm is a popular and effective RL algorithm. It's a type of policy gradient method, meaning it directly learns and optimizes the policy (a strategy for choosing actions) by adjusting the parameters of a policy function.\n",
    "\n",
    "Try out various hyperparameter configurations, for example:\n",
    "\n",
    "- learning_rate\n",
    "- gamma\n",
    "- n_steps\n",
    "- batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b256186-dff3-4a44-b6f7-45d6c1c3cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: experiment with different hyperparameters\n",
    "model = PPO('MlpPolicy', env, learning_rate=3e-4, gamma=0.99, n_steps=1024, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653f2a7-b840-4c64-95a3-13ea80c7db62",
   "metadata": {},
   "source": [
    "## Train the Agent\n",
    "\n",
    "With an RL agent chosen, now we start the training phase. Use the `learn()` method on your agent. You will need to pass in a value for the parameter `total_timesteps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d23898f-3c00-4d0b-a200-767b7e12558f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1a1417050>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: use the `learn` method on the `model` and supply a value for `total_timesteps`\n",
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b76453-526f-40cf-a2cf-02c6fa490265",
   "metadata": {},
   "source": [
    "## Save the Trained Model\n",
    "\n",
    "Because training can take SOOOO long, you typically want to save the results of your trained model to an external file. The code below will save the model to a `zip` file on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd709cde-5b56-4557-b8a1-e60edb03cf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to cartpole_ppo_model\n"
     ]
    }
   ],
   "source": [
    "# save the trained model\n",
    "model_filename = 'cartpole_ppo_model'\n",
    "model.save(model_filename)\n",
    "print(f'Model saved to {model_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551d97ab-d091-481c-9c62-61ec9e12abb9",
   "metadata": {},
   "source": [
    "## Load the Trained Model\n",
    "\n",
    "With the model saved, we can load this in to the notebook and continue on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e24f795-e1ab-4969-b84c-04cb790eddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "loaded_model = PPO.load(model_filename, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6649bd-948e-4b0f-b3a0-e4c2ea4d2ef7",
   "metadata": {},
   "source": [
    "## Evaluate the Agent\n",
    "\n",
    "The moment of truth: how does the trained model fare in the environment? Complete the **TODO** tasks to see how your model does. You will need to look up the docs for how the [`predict`](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html) and [`step`](https://gymnasium.farama.org/api/env/) methods work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4843d9f9-d9d6-48c3-a814-40acb7eb012c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward over 5 episodes: 100.0\n"
     ]
    }
   ],
   "source": [
    "# evaluate the agent\n",
    "num_evaluation_steps = 5\n",
    "mean_reward = 0\n",
    "for i in range(num_evaluation_steps):\n",
    "    obs, _ = env.reset()\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    episode_reward = 0\n",
    "    while not terminated and not truncated:\n",
    "        # TODO: use the `predict` method on the `loaded_model`\n",
    "        action, states = loaded_model.predict(obs, deterministic=True)\n",
    "        \n",
    "        # TODO: use the `step` method on the `env`\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        # TODO: update the `episode_reward` with the new reward\n",
    "        episode_reward += reward\n",
    "\n",
    "        # possibly render the environment\n",
    "        if render_flag:\n",
    "            env.render()\n",
    "\n",
    "    # TODO: update the `mean_reward` with the `episode_reward`\n",
    "mean_reward += episode_reward\n",
    "\n",
    "# TODO: complete the computation of `mean_reward`\n",
    "mean_reward /= num_evaluation_steps\n",
    "\n",
    "# display the information\n",
    "print(f'Mean reward over {num_evaluation_steps} episodes: {mean_reward}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aba88a0-01ce-4021-83fd-c3111d6e8742",
   "metadata": {},
   "source": [
    "## Close the Environment\n",
    "\n",
    "The last thing to do when using Gymnasium is to close out the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c82ac40-f293-4c12-b1d3-4095f643f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1bfa02-f33e-4b1b-b1a6-937749ab5583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
